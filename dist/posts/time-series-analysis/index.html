<!DOCTYPE html><html lang="en"> <head><title>Time Series Forecasting with LSTM</title><meta charset="UTF-8"><link rel="canonical" href="https://binaryash.github.io/posts/time-series-analysis/"><meta name="description" content="LSTM networks for forecasting airline passenger counts using time series data."><meta name="robots" content="index, follow"><meta property="og:title" content="Time Series Forecasting with LSTM"><meta property="og:type" content="website"><meta property="og:image" content="/opengraph-image.jpg"><meta property="og:url" content="https://binaryash.github.io/posts/time-series-analysis/"><meta property="og:image:url" content="/opengraph-image.jpg"><meta property="og:image:alt" content="binaryash portfolio"><meta name="twitter:creator" content="@itsstormzz_"><link rel="icon" href="/favicon.svg"><link rel="sitemap" href="/sitemap-index.xml"><meta content="width=device-width, initial-scale=1" name="viewport"><meta content="Astro v4.5.12" name="generator"><meta content="/opengraph-image.jpg" name="twitter:image"><meta content="summary_large_image" name="twitter:card"><meta content="Time Series Forecasting with LSTM" name="twitter:title"><meta content="Portfolio of BinaryAsh" name="twitter:description"><meta content="@itsstormzz_" name="twitter:site"><style>@font-face {font-weight: 400;font-style: normal;font-family: Open Sans;font-display: swap;src: url(https://fonts.gstatic.com/s/opensans/v40/memSYaGs126MiZpBA-UvWbX2vVnXBbObj2OVZyOOSr4dVJWUgsjZ0C4n.ttf)}</style><style>html { font-family: Open Sans, '_font_fallback_1064848275918', sans-serif; } :root{ --font-open-sans: Open Sans, '_font_fallback_1064848275918', sans-serif; } @font-face { font-family: '_font_fallback_1064848275918'; size-adjust: 105.22%; src: local('Arial'); ascent-override: 101.58%; descent-override: 27.84%; line-gap-override: 0.00%; }</style><link rel="stylesheet" href="/_astro/about.DHBZIb36.css"></head><body class="mx-auto flex min-h-screen max-w-[872px] flex-col gap-9 bg-neutral-950 px-10 py-8 text-sm text-neutral-400 md:gap-20 md:py-16"> <header class="z-40 flex w-full flex-col gap-2 md:flex-row md:justify-between"> <a href="mailto:binaryash@hotmail.com" class="hover:text-neutral-100">binaryash@hotmail.com</a> <nav role="navigation"> <ul role="list" class="flex flex-row gap-2"> <li> <a href="/" class="hover:text-neutral-100">Home</a> </li> <li>/</li> <li> <a href="/posts" class="hover:text-neutral-100">Posts</a> </li> <li>/</li><li></li><li> <a href="/about" class="hover:text-neutral-100">About</a> </li> <li>/</li><li></li><li> <a href="/ash-resume.pdf" class="hover:text-neutral-100">Resume</a> </li> </ul> </nav> </header> <div class="fixed z-0 h-[134px] w-[134px] lg:w-[300px] lg:h-[300px] rounded-full bg-orange-500 blur-[150px] md:blur-[350px] opacity-50 left-0 top-0"></div> <div class="fixed z-0 h-[134px] w-[134px] lg:w-[300px] lg:h-[300px] rounded-full bg-violet-500 blur-[150px] md:blur-[350px] opacity-50 right-0 bottom-0"></div>  <main class="post mx-auto flex w-full max-w-prose flex-col gap-4"> <header role="presentation"> <h1 class="text-md"> Time Series Forecasting with LSTM - 24/12/2024 </h1> <p class="italic">LSTM networks for forecasting airline passenger counts using time series data.</p> </header> <h2 id="time-series-forecasting-with-lstm">Time Series Forecasting with LSTM</h2>
<p>In this post, we will delve into the application of <strong>Long Short-Term Memory (LSTM)</strong> networks for <strong>time series forecasting</strong>, specifically predicting future airline passenger counts based on historical data. LSTM, a specialized variant of Recurrent Neural Networks (RNNs), excels at handling sequential data by capturing long-term dependencies in time series. This makes it highly effective for tasks such as forecasting, where patterns evolve over time and past data points influence future predictions.</p>
<p>The dataset we will use for this project is the <strong>Airline Passengers dataset</strong>, which provides monthly counts of international airline passengers between 1949 and 1960. Time series forecasting plays a critical role in airline operations, helping companies predict demand, allocate resources effectively, and optimize pricing. For example, accurately predicting passenger traffic enables airlines to adjust their schedules, improve customer satisfaction, and manage operational costs efficiently.</p>
<p>Before building the LSTM model, the dataset must be preprocessed. Time series data is typically non-stationary, meaning its statistical properties such as mean and variance change over time. This makes it necessary to scale the data to a consistent range, which can be achieved using normalization techniques like <strong>MinMax Scaling</strong>. Scaling transforms all values to fall within a specific range, typically between 0 and 1, making it easier for the model to learn from the data.</p>
<pre class="astro-code nord" style="background-color:#2e3440ff;color:#d8dee9ff; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color:#81A1C1">from</span><span style="color:#D8DEE9FF"> sklearn</span><span style="color:#ECEFF4">.</span><span style="color:#D8DEE9FF">preprocessing </span><span style="color:#81A1C1">import</span><span style="color:#D8DEE9FF"> MinMaxScaler</span></span>
<span class="line"></span>
<span class="line"><span style="color:#616E88"># Scale the dataset to range [0, 1]</span></span>
<span class="line"><span style="color:#D8DEE9FF">scaler </span><span style="color:#81A1C1">=</span><span style="color:#88C0D0"> MinMaxScaler</span><span style="color:#ECEFF4">(</span><span style="color:#D8DEE9">feature_range</span><span style="color:#81A1C1">=</span><span style="color:#ECEFF4">(</span><span style="color:#B48EAD">0</span><span style="color:#ECEFF4">,</span><span style="color:#B48EAD"> 1</span><span style="color:#ECEFF4">))</span></span>
<span class="line"><span style="color:#D8DEE9FF">dataset_scaled </span><span style="color:#81A1C1">=</span><span style="color:#D8DEE9FF"> scaler</span><span style="color:#ECEFF4">.</span><span style="color:#88C0D0">fit_transform</span><span style="color:#ECEFF4">(</span><span style="color:#D8DEE9FF">dataset</span><span style="color:#ECEFF4">)</span></span>
<span class="line"></span></code></pre>
<p>Once the data is scaled, we split it into <strong>training</strong> and <strong>testing</strong> sets. The training set is used to build and train the model, while the testing set evaluates its performance. Additionally, since LSTM models expect data in a specific format, we reshape the dataset into sequences of values where each input (X) consists of a window of previous data points used to predict the next value (Y). This is where the concept of <strong>look-back</strong> comes into play: it defines how many previous months of data the model should consider when making a prediction.</p>
<pre class="astro-code nord" style="background-color:#2e3440ff;color:#d8dee9ff; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color:#81A1C1">def</span><span style="color:#88C0D0"> create_dataset</span><span style="color:#ECEFF4">(</span><span style="color:#D8DEE9">dataset</span><span style="color:#ECEFF4">,</span><span style="color:#D8DEE9"> look_back</span><span style="color:#81A1C1">=</span><span style="color:#B48EAD">1</span><span style="color:#ECEFF4">):</span></span>
<span class="line"><span style="color:#D8DEE9FF">    dataX</span><span style="color:#ECEFF4">,</span><span style="color:#D8DEE9FF"> dataY </span><span style="color:#81A1C1">=</span><span style="color:#ECEFF4"> [],</span><span style="color:#ECEFF4"> []</span></span>
<span class="line"><span style="color:#81A1C1">    for</span><span style="color:#D8DEE9FF"> i </span><span style="color:#81A1C1">in</span><span style="color:#88C0D0"> range</span><span style="color:#ECEFF4">(</span><span style="color:#88C0D0">len</span><span style="color:#ECEFF4">(</span><span style="color:#D8DEE9FF">dataset</span><span style="color:#ECEFF4">)</span><span style="color:#81A1C1"> -</span><span style="color:#D8DEE9FF"> look_back </span><span style="color:#81A1C1">-</span><span style="color:#B48EAD"> 1</span><span style="color:#ECEFF4">):</span></span>
<span class="line"><span style="color:#D8DEE9FF">        a </span><span style="color:#81A1C1">=</span><span style="color:#D8DEE9FF"> dataset</span><span style="color:#ECEFF4">[</span><span style="color:#D8DEE9FF">i</span><span style="color:#ECEFF4">:(</span><span style="color:#D8DEE9FF">i </span><span style="color:#81A1C1">+</span><span style="color:#D8DEE9FF"> look_back</span><span style="color:#ECEFF4">),</span><span style="color:#B48EAD"> 0</span><span style="color:#ECEFF4">]</span></span>
<span class="line"><span style="color:#D8DEE9FF">        dataX</span><span style="color:#ECEFF4">.</span><span style="color:#88C0D0">append</span><span style="color:#ECEFF4">(</span><span style="color:#D8DEE9FF">a</span><span style="color:#ECEFF4">)</span></span>
<span class="line"><span style="color:#D8DEE9FF">        dataY</span><span style="color:#ECEFF4">.</span><span style="color:#88C0D0">append</span><span style="color:#ECEFF4">(</span><span style="color:#D8DEE9FF">dataset</span><span style="color:#ECEFF4">[</span><span style="color:#D8DEE9FF">i </span><span style="color:#81A1C1">+</span><span style="color:#D8DEE9FF"> look_back</span><span style="color:#ECEFF4">,</span><span style="color:#B48EAD"> 0</span><span style="color:#ECEFF4">])</span></span>
<span class="line"><span style="color:#81A1C1">    return</span><span style="color:#D8DEE9FF"> numpy</span><span style="color:#ECEFF4">.</span><span style="color:#88C0D0">array</span><span style="color:#ECEFF4">(</span><span style="color:#D8DEE9FF">dataX</span><span style="color:#ECEFF4">),</span><span style="color:#D8DEE9FF"> numpy</span><span style="color:#ECEFF4">.</span><span style="color:#88C0D0">array</span><span style="color:#ECEFF4">(</span><span style="color:#D8DEE9FF">dataY</span><span style="color:#ECEFF4">)</span></span>
<span class="line"></span></code></pre>
<p>The next step is constructing the <strong>LSTM model</strong>. The LSTM network is designed to learn patterns from sequential data, making it a perfect fit for time series forecasting. The LSTM layer helps the model remember important information from past time steps, while the Dense layer produces the final prediction. The model is trained using <strong>mean squared error</strong> (MSE) as the loss function and <strong>Adam optimizer</strong>, which adjusts the model’s weights during training to minimize the error.</p>
<pre class="astro-code nord" style="background-color:#2e3440ff;color:#d8dee9ff; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color:#81A1C1">from</span><span style="color:#D8DEE9FF"> keras</span><span style="color:#ECEFF4">.</span><span style="color:#D8DEE9FF">models </span><span style="color:#81A1C1">import</span><span style="color:#D8DEE9FF"> Sequential</span></span>
<span class="line"><span style="color:#81A1C1">from</span><span style="color:#D8DEE9FF"> keras</span><span style="color:#ECEFF4">.</span><span style="color:#D8DEE9FF">layers </span><span style="color:#81A1C1">import</span><span style="color:#D8DEE9FF"> LSTM</span><span style="color:#ECEFF4">,</span><span style="color:#D8DEE9FF"> Dense</span></span>
<span class="line"></span>
<span class="line"><span style="color:#616E88"># Build the LSTM model</span></span>
<span class="line"><span style="color:#D8DEE9FF">model </span><span style="color:#81A1C1">=</span><span style="color:#88C0D0"> Sequential</span><span style="color:#ECEFF4">()</span></span>
<span class="line"><span style="color:#D8DEE9FF">model</span><span style="color:#ECEFF4">.</span><span style="color:#88C0D0">add</span><span style="color:#ECEFF4">(</span><span style="color:#88C0D0">LSTM</span><span style="color:#ECEFF4">(</span><span style="color:#B48EAD">4</span><span style="color:#ECEFF4">,</span><span style="color:#D8DEE9"> input_shape</span><span style="color:#81A1C1">=</span><span style="color:#ECEFF4">(</span><span style="color:#B48EAD">1</span><span style="color:#ECEFF4">,</span><span style="color:#D8DEE9FF"> look_back</span><span style="color:#ECEFF4">)))</span></span>
<span class="line"><span style="color:#D8DEE9FF">model</span><span style="color:#ECEFF4">.</span><span style="color:#88C0D0">add</span><span style="color:#ECEFF4">(</span><span style="color:#88C0D0">Dense</span><span style="color:#ECEFF4">(</span><span style="color:#B48EAD">1</span><span style="color:#ECEFF4">))</span></span>
<span class="line"><span style="color:#D8DEE9FF">model</span><span style="color:#ECEFF4">.</span><span style="color:#88C0D0">compile</span><span style="color:#ECEFF4">(</span><span style="color:#D8DEE9">loss</span><span style="color:#81A1C1">=</span><span style="color:#ECEFF4">'</span><span style="color:#A3BE8C">mean_squared_error</span><span style="color:#ECEFF4">'</span><span style="color:#ECEFF4">,</span><span style="color:#D8DEE9"> optimizer</span><span style="color:#81A1C1">=</span><span style="color:#ECEFF4">'</span><span style="color:#A3BE8C">adam</span><span style="color:#ECEFF4">'</span><span style="color:#ECEFF4">)</span></span>
<span class="line"><span style="color:#D8DEE9FF">model</span><span style="color:#ECEFF4">.</span><span style="color:#88C0D0">fit</span><span style="color:#ECEFF4">(</span><span style="color:#D8DEE9FF">trainX</span><span style="color:#ECEFF4">,</span><span style="color:#D8DEE9FF"> trainY</span><span style="color:#ECEFF4">,</span><span style="color:#D8DEE9"> epochs</span><span style="color:#81A1C1">=</span><span style="color:#B48EAD">100</span><span style="color:#ECEFF4">,</span><span style="color:#D8DEE9"> batch_size</span><span style="color:#81A1C1">=</span><span style="color:#B48EAD">1</span><span style="color:#ECEFF4">,</span><span style="color:#D8DEE9"> verbose</span><span style="color:#81A1C1">=</span><span style="color:#B48EAD">2</span><span style="color:#ECEFF4">)</span></span>
<span class="line"></span></code></pre>
<p>After training, we evaluate the model’s performance by making predictions on both the training and testing datasets. The predicted values are then inverse-transformed back to their original scale, allowing us to compare them to the actual values. We assess the model’s accuracy using <strong>Root Mean Squared Error (RMSE)</strong>, a common metric for time series forecasting, which measures the average difference between predicted and actual values. By visualizing the predicted and actual values on a graph, we can gain insights into how well the model captures the underlying trends in the data.</p>
<p>LSTM networks provide a powerful tool for time series forecasting by learning from historical data and predicting future values. This approach is widely applicable in industries where predicting trends is essential for decision-making, such as finance, retail, and healthcare. By fine-tuning the model and exploring additional features or advanced architectures, we can improve forecasting accuracy and create even more robust predictive models for real-world applications.</p> </main>  </body></html>